{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml.html import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiki_age_scrape(names):\n",
    "    age = ''\n",
    "    for name in names:\n",
    "        if name in ages.keys():\n",
    "            print \"%s already in dictionary!\" %name\n",
    "        else:\n",
    "            print \"getting info for %s....\" %name\n",
    "            chromedriver = \"/Applications/chromedriver\"\n",
    "            os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            driver.get(\"https://www.wikipedia.org/\")\n",
    "            e = driver.find_element_by_name('search')\n",
    "            e.send_keys(name)\n",
    "            e.send_keys(Keys.RETURN)\n",
    "            soup = BeautifulSoup(driver.page_source)\n",
    "            try:\n",
    "                bday = soup.find(\"span\", {\"class\": \"bday\"}).text.strip().encode('ascii', 'ignore')\n",
    "                print \"%s: %s\" % (name, bday)\n",
    "                ages[name] = bday\n",
    "                driver.close()\n",
    "            except:\n",
    "                print \"no age information for %s!\" %name\n",
    "    return ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_salary_imdb(names):\n",
    "    for name in names:\n",
    "        movies = []\n",
    "        salaries = []\n",
    "        print name\n",
    "        filename = \"/Users/kpully/ds/metisgit/nyc16_ds8/projects/02-luther/csvs/%s salary.csv\" %name\n",
    "        if name in names_none:\n",
    "            print 'already checked, no salary info!'\n",
    "            print \"_____________________________________\"\n",
    "        elif os.path.isfile(filename):\n",
    "            print \"%s already exists!\" %filename\n",
    "            print \"_____________________________________\"\n",
    "        else:\n",
    "            print \"Getting information for %s.....\" %name\n",
    "            chromedriver = \"/Applications/chromedriver\"\n",
    "            os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            driver.get(\"http://www.imdb.com/?ref_=nv_home\")\n",
    "            SEARCH_BUTTON_XPATH = '//input[@type=\"text\" and @id=\"navbar-query\"]'\n",
    "            e = driver.find_element_by_xpath(SEARCH_BUTTON_XPATH)\n",
    "            e.send_keys(name)\n",
    "            e.send_keys(Keys.RETURN)\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "\n",
    "            td = soup.find('td', {\"class\": \"result_text\"})\n",
    "            url = td.find('a').get('href')\n",
    "            url = 'http://www.imdb.com' + url\n",
    "            driver.get(url) \n",
    "            try:\n",
    "                bio = driver.find_element_by_link_text('Biography')\n",
    "                bio.click()\n",
    "            except:\n",
    "                print \"no biography exists!\"\n",
    "                names_none.add(name)\n",
    "                print \"_____________________________________\"\n",
    "            else:\n",
    "                try:\n",
    "                    salary = driver.find_element_by_link_text('Salary')\n",
    "                    salary.click()\n",
    "                except:\n",
    "                    print \"no salary information available!\"\n",
    "                    names_none.add(name)\n",
    "                    print \"_____________________________________\"\n",
    "                else:\n",
    "                    #html = driver.page_source\n",
    "                    #soup = BeautifulSoup(html, \"lxml\")\n",
    "                    url = driver.current_url\n",
    "                    page = parse(url)\n",
    "                    xp = '//table[@id=\"salariesTable\"]'\n",
    "                    rows = page.xpath(xp)\n",
    "                    rows = rows[0].text_content().replace('\\n', '').strip().encode('ascii', 'ignore')\n",
    "\n",
    "                    data = []\n",
    "                    for row in rows.strip().split('     '):\n",
    "                        data.append(row.strip())\n",
    "                    data = filter(None, data)\n",
    "                    movies = data[::2]\n",
    "                    print movies\n",
    "                    salaries = data[1::2]\n",
    "                    print salaries\n",
    "                    df = pd.DataFrame({'movie': movies, 'salary': salaries})\n",
    "                    df.to_csv('/Users/kpully/ds/metisgit/nyc16_ds8/projects/02-luther/csvs/%s salary.csv' %name, encoding='utf-8')\n",
    "                    print \"_____________________________________\"\n",
    "\n",
    "            driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url_imdb(name):\n",
    "    chromedriver = \"/Applications/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(\"http://www.imdb.com/?ref_=nv_home\")\n",
    "    print name\n",
    "    SEARCH_BUTTON_XPATH = '//input[@type=\"text\" and @id=\"navbar-query\"]'\n",
    "    e = driver.find_element_by_xpath(SEARCH_BUTTON_XPATH)\n",
    "    e.send_keys(name)\n",
    "    e.send_keys(Keys.RETURN)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    td = soup.find('td', {\"class\": \"result_text\"})\n",
    "    url = td.find('a').get('href')\n",
    "    url = 'http://www.imdb.com' + url\n",
    "\n",
    "    driver.close()\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filmography_imdb(name, url): \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    movies = []\n",
    "    years = []\n",
    "    for film in soup.find_all('div',{ \"class\" : \"filmo-row\" }):\n",
    "        #print film\n",
    "        year = film.find('span', {\"class\": \"year_column\"}).text.strip()\n",
    "        years.append(year)\n",
    "        movie = film.find('a').text\n",
    "        movies.append(movie)\n",
    "        df = pd.DataFrame({'movie' : movies, 'year' : years})\n",
    "        df.to_csv('%s.csv' %name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url_list_imdb(names):\n",
    "    for name in names:\n",
    "        filename = \"/Users/kpully/ds/metisgit/nyc16_ds8/projects/02-luther/csvs/%s.csv\" %name\n",
    "        filename_other = \"/Users/kpully/ds/metisgit/nyc16_ds8/projects/02-luther/%s.csv\" %name\n",
    "        if os.path.isfile(filename):\n",
    "            print \"%s already exists!\" %filename\n",
    "        elif os.path.isfile(filename_other):\n",
    "            print \"%s already exists!\" %filename_other\n",
    "        else:\n",
    "            chromedriver = \"/Applications/chromedriver\"\n",
    "            os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            driver.get(\"http://www.imdb.com/?ref_=nv_home\")\n",
    "            print name\n",
    "            SEARCH_BUTTON_XPATH = '//input[@type=\"text\" and @id=\"navbar-query\"]'\n",
    "            e = driver.find_element_by_xpath(SEARCH_BUTTON_XPATH)\n",
    "            e.send_keys(name)\n",
    "            e.send_keys(Keys.RETURN)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "\n",
    "            td = soup.find('td', {\"class\": \"result_text\"})\n",
    "            url = td.find('a').get('href')\n",
    "            url = 'http://www.imdb.com' + url\n",
    "\n",
    "            driver.close()\n",
    "\n",
    "            get_filmography(name, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sex(names):\n",
    "    for name in names:\n",
    "        if name in sexes.keys():\n",
    "            print \"%s already in dict!\" %name\n",
    "        else:\n",
    "            chromedriver = \"/Applications/chromedriver\"\n",
    "            os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            driver.get(\"http://www.imdb.com/?ref_=nv_home\")\n",
    "\n",
    "            SEARCH_BUTTON_XPATH = '//input[@type=\"text\" and @id=\"navbar-query\"]'\n",
    "            e = driver.find_element_by_xpath(SEARCH_BUTTON_XPATH)\n",
    "            e.send_keys(name)\n",
    "            e.send_keys(Keys.RETURN)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "\n",
    "            td = soup.find('td', {\"class\": \"result_text\"})\n",
    "            url = td.find('a').get('href')\n",
    "            url = 'http://www.imdb.com' + url\n",
    "\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "            try:\n",
    "                sex = soup.find('span', {'itemprop': 'jobTitle'}).text.strip()\n",
    "            except: \n",
    "                print \"can't find sex info!\"\n",
    "            sexes[name] = sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
